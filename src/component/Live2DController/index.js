import PropTypes from 'prop-types';
import React, { forwardRef, useEffect, useImperativeHandle, useRef, useState } from 'react';
import {
  calculateMouthForm,
  calculateMouthOpenFromVolume,
  createPIXIApp,
  LIVE2D_CONFIG,
  loadLive2DModel,
  setModelMouthParameters,
  waitForLive2DScripts,
} from '../../common/constants/live2d';

/**
 * Live2D æ§åˆ¶å™¨ç»„ä»¶
 *
 * åŠŸèƒ½ç‰¹æ€§ï¼š
 * - ğŸ­ Live2Dæ¨¡å‹åŠ è½½å’Œæ˜¾ç¤º
 * - ğŸµ å®æ—¶å£å‹åŒæ­¥ï¼ˆåŸºäºéŸ³é¢‘åˆ†æï¼‰
 * - ğŸ˜Š è¡¨æƒ…æ§åˆ¶ï¼ˆæ”¯æŒå¤šç§è¡¨æƒ…åˆ‡æ¢ï¼‰
 * - ğŸ“Š éŸ³é‡ç›‘æµ‹å’Œè°ƒè¯•ä¿¡æ¯
 * - ğŸ”§ çµæ´»çš„é…ç½®é€‰é¡¹
 */

/**
 * Live2D Controller Component
 * @param {Object} props - ç»„ä»¶å±æ€§
 * @param {boolean} props.visible - æ˜¯å¦æ˜¾ç¤ºç»„ä»¶
 * @param {string} props.modelUrl - Live2Dæ¨¡å‹URL
 * @param {number} props.width - ç”»å¸ƒå®½åº¦
 * @param {number} props.height - ç”»å¸ƒé«˜åº¦
 * @param {number} props.scale - æ¨¡å‹ç¼©æ”¾æ¯”ä¾‹
 * @param {Object} props.position - æ¨¡å‹ä½ç½®
 * @param {boolean} props.showDebugInfo - æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
 * @param {Function} props.onModelLoaded - æ¨¡å‹åŠ è½½å®Œæˆå›è°ƒ
 * @param {Function} props.onError - é”™è¯¯å›è°ƒ
 * @param {string} props.className - CSSç±»å
 * @param {Object} props.style - å†…è”æ ·å¼
 * @param {Object} ref - React ref
 */
const Live2DController = forwardRef(
  (
    {
      visible = true,
      modelUrl = LIVE2D_CONFIG.DEFAULT_MODEL_URL,
      width = 600,
      height = 600,
      scale = LIVE2D_CONFIG.DEFAULT_SCALE,
      position = LIVE2D_CONFIG.DEFAULT_POSITION,
      onModelLoaded,
      onError,
      className = '',
      style = {},
    },
    ref
  ) => {
    // ç»„ä»¶çŠ¶æ€
    const [isReady, setIsReady] = useState(false);
    const [isInited, setIsInited] = useState(false);
    const [currentExpression, setCurrentExpression] = useState('neutral');
    const [debugInfo, setDebugInfo] = useState({
      volume: 0,
      mouthOpen: 0,
      mouthForm: 0,
      syncStatus: 'å¾…æœº',
    });

    // å¼•ç”¨
    const canvasRef = useRef(null);
    const appRef = useRef(null);
    const modelRef = useRef(null);
    const isLoadingRef = useRef(false);

    // åŠ¨ç”»æ§åˆ¶
    const animationRef = useRef({
      id: null,
      isRunning: false,
    });

    // éŸ³é¢‘åˆ†æç›¸å…³
    const audioAnalysisRef = useRef({
      analyser: null,
      volumeData: new Uint8Array(LIVE2D_CONFIG.AUDIO_ANALYSIS.FFT_SIZE),
      isActive: false,
      volumeThreshold: LIVE2D_CONFIG.AUDIO_ANALYSIS.VOLUME_THRESHOLD,
      smoothingFactor: LIVE2D_CONFIG.AUDIO_ANALYSIS.SMOOTHING_FACTOR,
      currentMouthOpen: 0,
      currentMouthForm: 0,
    });

    // æš´éœ²ç»™çˆ¶ç»„ä»¶çš„API
    useImperativeHandle(
      ref,
      () => ({
        // è¡¨æƒ…æ§åˆ¶
        setExpression: expressionName => {
          if (expressionName) {
            console.log('ğŸ­ è®¾ç½®è¡¨æƒ…:', expressionName);
            setExpressionInternal(expressionName);
          } else {
            console.warn(`ä¸æ”¯æŒçš„è¡¨æƒ…: ${expressionName}`);
          }
        },

        // è·å–æ”¯æŒçš„è¡¨æƒ…åˆ—è¡¨
        getSupportedExpressions: () => Object.keys(LIVE2D_CONFIG.EXPRESSIONS),

        // å£å‹æ§åˆ¶ï¼ˆæ‰‹åŠ¨è®¾ç½®ï¼‰
        setMouthParameters: (openY, form = 0) => {
          setMouthParametersInternal(openY, form);
        },

        // è¿æ¥éŸ³é¢‘åˆ†æå™¨è¿›è¡Œè‡ªåŠ¨å£å‹åŒæ­¥
        connectAudioAnalyser: analyser => {
          connectAudioAnalyserInternal(analyser);
        },

        // æ–­å¼€éŸ³é¢‘åˆ†æå™¨
        disconnectAudioAnalyser: () => {
          disconnectAudioAnalyserInternal();
        },

        // è·å–æ¨¡å‹çŠ¶æ€
        getModelState: () => ({
          isReady,
          currentExpression,
          debugInfo,
        }),

        // é‡æ–°åŠ è½½æ¨¡å‹
        reloadModel: () => {
          if (!isLoadingRef.current) {
            loadLive2DModelInternal();
          }
        },
      }),
      [isReady, currentExpression, debugInfo]
    );

    // åˆå§‹åŒ–ç»„ä»¶
    useEffect(() => {
      if (visible && canvasRef.current && !isLoadingRef.current) {
        initializeLive2D();
      }

      return () => {
        cleanup();
      };
    }, [visible, modelUrl]);

    // åˆå§‹åŒ–Live2D
    const initializeLive2D = async () => {
      if (isLoadingRef.current) return;
      isLoadingRef.current = true;

      try {
        console.log('ğŸ­ å¼€å§‹åˆå§‹åŒ–Live2Dæ§åˆ¶å™¨...');

        // ç­‰å¾…è„šæœ¬åŠ è½½
        await waitForLive2DScripts();
        console.log('âœ… Live2Dè„šæœ¬åŠ è½½å®Œæˆ');

        await loadLive2DModelInternal();
      } catch (error) {
        console.error('âŒ Live2Dåˆå§‹åŒ–å¤±è´¥:', error);
        onError?.(error);
      } finally {
        isLoadingRef.current = false;
      }
    };

    // åŠ è½½Live2Dæ¨¡å‹
    const loadLive2DModelInternal = async () => {
      try {
        // æ¸…ç†æ—§çš„åº”ç”¨
        if (appRef.current) {
          appRef.current.destroy(true);
          appRef.current = null;
        }

        // ä½¿ç”¨å¸®åŠ©å‡½æ•°åˆ›å»ºPIXIåº”ç”¨
        appRef.current = createPIXIApp(canvasRef.current, {
          width,
          height,
          backgroundAlpha: 0,
          backgroundColor: 0x000000,
          transparent: true,
          autoStart: true,
          antialias: true,
          preserveDrawingBuffer: true, // å¯èƒ½éœ€è¦è¿™ä¸ª
        });

        // å¦‚æœä¸Šé¢ä¸è¡Œï¼Œå°è¯•æ‰‹åŠ¨è®¾ç½®
        // if (appRef.current.renderer) {
        //   appRef.current.renderer.background.alpha = 0;
        // }

        console.log('âœ… PIXIåº”ç”¨åˆ›å»ºæˆåŠŸ');

        // ä½¿ç”¨å¸®åŠ©å‡½æ•°åŠ è½½Live2Dæ¨¡å‹
        modelRef.current = await loadLive2DModel(modelUrl, {
          autoInteract: false,
        });

        console.log('âœ… Live2Dæ¨¡å‹åŠ è½½æˆåŠŸ');

        // åœæ­¢è‡ªåŠ¨åŠ¨ä½œå’Œè¡¨æƒ…
        if (modelRef.current.internalModel.motionManager) {
          modelRef.current.internalModel.motionManager.stopAllMotions();
          // ç¦ç”¨idleåŠ¨ä½œ
          modelRef.current.internalModel.motionManager.groups.idle = null;
          modelRef.current.internalModel.motionManager.groups.Idle = null;
        }

        // æ·»åŠ åˆ°èˆå°
        appRef.current.stage.addChild(modelRef.current);

        // è®¾ç½®ä½ç½®å’Œç¼©æ”¾
        modelRef.current.scale.set(scale);
        modelRef.current.x = position.x;
        modelRef.current.y = position.y;

        setIsReady(true);
        setIsInited(true);
        console.log('ğŸ‰ Live2Dæ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ');

        onModelLoaded?.(modelRef.current);
      } catch (error) {
        console.error('âŒ Live2Dæ¨¡å‹åŠ è½½å¤±è´¥:', error);
        throw error;
      }
    };

    useEffect(() => {
      if (isReady && isInited) {
        startVolumeMonitoring();
      }

      // æ¸…ç†å‡½æ•°
      return () => {
        stopVolumeMonitoring();
      };
    }, [isReady, isInited]);

    // è®¾ç½®è¡¨æƒ…
    const setExpressionInternal = expressionName => {
      if (!modelRef.current || !isReady) {
        console.warn('æ¨¡å‹æœªå‡†å¤‡å¥½ï¼Œæ— æ³•è®¾ç½®è¡¨æƒ…');
        return false;
      }

      try {
        modelRef.current.expression(expressionName);
        setCurrentExpression(expressionName);
        console.log(`âœ… è®¾ç½®è¡¨æƒ…: ${expressionName}`);
        return true;
      } catch (error) {
        console.error(`âŒ è®¾ç½®è¡¨æƒ…å¤±è´¥: ${expressionName}`, error);
        return false;
      }
    };

    // è®¾ç½®å£å‹å‚æ•°
    const setMouthParametersInternal = (openY, form = 0) => {
      if (!modelRef.current || !modelRef.current.internalModel || !isReady) {
        return false;
      }

      // ä½¿ç”¨å¸®åŠ©å‡½æ•°è®¾ç½®å£å‹å‚æ•°
      const success = setModelMouthParameters(modelRef.current, openY, form);

      if (success) {
        // æ›´æ–°è°ƒè¯•ä¿¡æ¯
        setDebugInfo(prev => ({
          ...prev,
          mouthOpen: openY,
          mouthForm: form,
        }));
      }

      return success;
    };

    // è¿æ¥éŸ³é¢‘åˆ†æå™¨
    const connectAudioAnalyserInternal = analyser => {
      if (!analyser) {
        console.warn('éŸ³é¢‘åˆ†æå™¨æ— æ•ˆ');
        return false;
      }

      audioAnalysisRef.current.analyser = analyser;
      audioAnalysisRef.current.isActive = true;
      audioAnalysisRef.current.volumeData = new Uint8Array(analyser.frequencyBinCount);

      console.log('âœ… éŸ³é¢‘åˆ†æå™¨å·²è¿æ¥ï¼Œå¼€å§‹å£å‹åŒæ­¥');
      return true;
    };

    // æ–­å¼€éŸ³é¢‘åˆ†æå™¨
    const disconnectAudioAnalyserInternal = () => {
      audioAnalysisRef.current.analyser = null;
      audioAnalysisRef.current.isActive = false;
      audioAnalysisRef.current.currentMouthOpen = 0;
      audioAnalysisRef.current.currentMouthForm = 0;

      console.log('ğŸ”‡ éŸ³é¢‘åˆ†æå™¨å·²æ–­å¼€');
    };

    // å¼€å§‹éŸ³é‡ç›‘æµ‹
    const startVolumeMonitoring = () => {
      // å¦‚æœå·²ç»åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢
      if (animationRef.current.isRunning) {
        stopVolumeMonitoring();
      }

      animationRef.current.isRunning = true;

      const updateVolume = () => {
        // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­è¿è¡Œ
        if (!animationRef.current.isRunning) {
          return;
        }

        const { analyser, volumeData, isActive, volumeThreshold, smoothingFactor } =
          audioAnalysisRef.current;

        if (analyser && isActive) {
          // è·å–é¢‘åŸŸæ•°æ®
          analyser.getByteFrequencyData(volumeData);

          // è®¡ç®—å¹³å‡éŸ³é‡
          let sum = 0;
          for (let i = 0; i < volumeData.length; i++) {
            sum += volumeData[i];
          }
          const avgVolume = sum / volumeData.length;

          // æ›´æ–°è°ƒè¯•ä¿¡æ¯
          setDebugInfo(prev => ({
            ...prev,
            volume: Math.round(avgVolume),
            syncStatus: avgVolume > volumeThreshold ? 'æ­£åœ¨åŒæ­¥' : 'é™éŸ³çŠ¶æ€',
          }));

          // ä½¿ç”¨å¸®åŠ©å‡½æ•°è®¡ç®—å£å‹å‚æ•°
          if (avgVolume > volumeThreshold) {
            const targetMouthOpen = calculateMouthOpenFromVolume(avgVolume);

            // å¹³æ»‘å¤„ç†
            audioAnalysisRef.current.currentMouthOpen =
              audioAnalysisRef.current.currentMouthOpen * smoothingFactor +
              targetMouthOpen * (1 - smoothingFactor);

            // ä½¿ç”¨å¸®åŠ©å‡½æ•°è®¡ç®—å˜´å‹å½¢çŠ¶å˜åŒ–
            audioAnalysisRef.current.currentMouthForm = calculateMouthForm();
          } else {
            // éŸ³é‡å¤ªå°ï¼Œé€æ¸é—­å˜´
            audioAnalysisRef.current.currentMouthOpen *= 0.9;
            audioAnalysisRef.current.currentMouthForm *= 0.9;
          }

          // åº”ç”¨åˆ°Live2Dæ¨¡å‹
          setMouthParametersInternal(
            audioAnalysisRef.current.currentMouthOpen,
            audioAnalysisRef.current.currentMouthForm
          );
        } else {
          // æ²¡æœ‰éŸ³é¢‘æ—¶é‡ç½®
          audioAnalysisRef.current.currentMouthOpen *= 0.95;
          audioAnalysisRef.current.currentMouthForm *= 0.95;
          setMouthParametersInternal(
            audioAnalysisRef.current.currentMouthOpen,
            audioAnalysisRef.current.currentMouthForm
          );

          setDebugInfo(prev => ({
            ...prev,
            syncStatus: 'å¾…æœº',
          }));
        }

        // ç»§ç»­ä¸‹ä¸€å¸§
        animationRef.current.id = requestAnimationFrame(updateVolume);
      };

      // å¼€å§‹åŠ¨ç”»å¾ªç¯
      animationRef.current.id = requestAnimationFrame(updateVolume);
    };

    // åœæ­¢éŸ³é‡ç›‘æµ‹
    const stopVolumeMonitoring = () => {
      animationRef.current.isRunning = false;

      if (animationRef.current.id) {
        cancelAnimationFrame(animationRef.current.id);
        animationRef.current.id = null;
      }
    };

    // æ¸…ç†èµ„æº
    const cleanup = () => {
      // åœæ­¢åŠ¨ç”»å¾ªç¯
      stopVolumeMonitoring();

      // æ–­å¼€éŸ³é¢‘åˆ†æå™¨
      disconnectAudioAnalyserInternal();

      modelRef.current.internalModel?.destroy();

      // æ¸…ç†PIXIåº”ç”¨
      if (appRef.current) {
        appRef.current.destroy(true);
        appRef.current = null;
      }

      // é‡ç½®çŠ¶æ€
      modelRef.current = null;
      setIsReady(false);
      setIsInited(false);
      isLoadingRef.current = false;
    };

    if (!visible) return null;

    return (
      <div
        className={`live2d-controller ${className}`}
        style={{
          position: 'relative',
          display: 'inline-block',
          // border: '2px solid #e1e5e9',
          borderRadius: '15px',
          background: 'transparent',
          overflow: 'hidden',
          ...style,
        }}
      >
        <canvas
          ref={canvasRef}
          style={{
            display: 'block',
            width: '100%',
            height: '100%',
            background: 'transparent',
          }}
        />
        {/* {!isReady && (
          <div
            style={{
              position: 'absolute',
              top: '50%',
              left: '50%',
              transform: 'translate(-50%, -50%)',
              background: 'rgba(255,255,255,0.9)',
              padding: '20px',
              borderRadius: '10px',
              textAlign: 'center',
            }}
          >
            <div>ğŸ­ æ­£åœ¨åŠ è½½Live2Dæ¨¡å‹...</div>
          </div>
        )} */}
      </div>
    );
  }
);

Live2DController.propTypes = {
  visible: PropTypes.bool,
  modelUrl: PropTypes.string,
  width: PropTypes.number,
  height: PropTypes.number,
  scale: PropTypes.number,
  position: PropTypes.shape({
    x: PropTypes.number,
    y: PropTypes.number,
  }),
  showDebugInfo: PropTypes.bool,
  onModelLoaded: PropTypes.func,
  onError: PropTypes.func,
  className: PropTypes.string,
  style: PropTypes.object,
};

Live2DController.displayName = 'Live2DController';

export default Live2DController;
